---
import Header from '~/components/widgets/Header.astro';
import Hero2 from '~/components/widgets/Hero2.astro';
import Content from '~/components/widgets/Content.astro';
// import Timeline from '~/components/ui/Timeline.astro';
import { headerData } from '~/navigation';
import FAQs from '~/components/widgets/FAQs.astro';
import Brands from '~/components/widgets/Brands.astro';
// import Timezone from '~/components/widgets/Timezone.astro';
import Layout from '~/layouts/PageLayout.astro';
// import Testimonials from '~/components/widgets/Testimonials.astro';
import Button from '~/components/ui/Button.astro';
// import Sponsor from '~/components/widgets/Sponsor.astro';
import Timezone from '~/components/widgets/Timezone.astro';
const metadata = {
  title: 'NeurIPS 2025 Workshop TrustLLM',
};
---

<Layout metadata={metadata}>
  <Fragment slot="header">
    <Header {...headerData} isSticky />
  </Fragment>

  <!-- Hero2 Widget ******************* -->

  <Hero2
    tagline="NeurIPS 2025 Workshop"
    actions={[
      { variant: 'secondary', text: 'NeurIPS Workshop Page', href: 'https://nips.cc/virtual/2025/workshop' },
      {
        variant: 'secondary',
        text: 'Submission Site',
        href: 'https://openreview.net/group?id=NeurIPS.cc/2025/Workshop_Proposals/',
      },
    ]}
  >
    <Fragment slot="title">Emergent Trust Risks in Large Reasoning Models (TrustLLM)</Fragment>

    <Fragment slot="subtitle">
      NeurIPS 2025 @ San Diego Convention Center, USA, Dec 6th - Dec 7th
      <!-- <br /> -->
      <!-- <span class="text-slate-300">Straus 1</span> -->
    </Fragment>

    <Fragment slot="content">
      <br />
      <!-- <span class="text-white"
        >The time for acceptance notification is delayed to Jun 19, 2024 EOD AoE</span
      > -->
    </Fragment>
  </Hero2>

  <!-- Content Widget **************** -->

  <!-- <Content id="Overview">
    <Fragment slot="title"> Overview </Fragment><Fragment slot="subtitle"
      >Welcome to the ICML 2024 Workshop on Trustworthy in Multi-modal Foundation Models and AI Agents (TiFA)
    </Fragment>
    <Fragment slot="content"
      ><div class="mb-4">
        Multi-modal Foundation Models (MFMs) have witnessed significant advancements in various bench marks and
        practical applications. They are proficient in a wide range of tasks, and capable of pro ducing varied
        multimodal responses. Nowadays a couple of MFMs have been deployed as realistic applications (such as GPT-4 [18]
        and Midjourney [25]). Meanwhile, a large variety of MFMs (like InternLM [24] and LLaVA [14]) are still under
        further research. Furthermore, foundation models with their powerful reasoning capabilities have led to the
        emergence of various AI Agents [19, 28]. These agents are often capable of understanding open-world
        instructions, breaking down complex tasks, and taking steps to achieve their goals.
      </div>
      <div class="mb-4">
        Advanced MFMs and AI Agents, equipped with diverse modalities and an increasing number of available affordances,
        accelerate their potential impact on society. As these systems gain abili ties to alter societal dynamics
        swiftly, understanding and preempting the vulnerabilities of such systems and their induced harms becomes
        crucial. Trustworthiness in MLMs and AI Agents tran scends identifying vulnerabilities in models and emphasizes
        the importance of proactive harm mit igation, safeguards, and the establishment of comprehensive safety
        mechanisms throughout the lifecycle of system development and deployment. This approach demands a blend of
        technical and socio-technical strategies, incorporating AI governance and regulatory insights to build
        trustworthy MFMs and Agents.
      </div>
    </Fragment>
    <Fragment slot="bg">
      <div class="absolute inset-0 bg-blue-50 dark:bg-transparent"></div>
    </Fragment>
  </Content> -->
  <Content id="Schedule">
    <Fragment slot="content">
      <h3 class="text-3xl font-bold tracking-tight dark:text-white sm:text-4xl mb-2 text-center">
        Schedule<br />
      </h3>
      <Timezone
        items={[
          {
            time: '2025-12-06T09:00:00-07:00',
            theme: {
              title: 'Opening Remark',
              // subtitles: ['LoremLoremLoremLorem', 'LoremLoremLoremLorem'],
            },
            Speaker: 'Wei Huang',
            title: 'Opening Remark',
            institution: 'Research Scientist, RIKEN AIP',
            logoSrc: '',
            link: 'https://weihuang05.github.io/',
            duration: '10',
          },
          {
            time: '2025-12-06T09:10:00-07:00',
            theme: {
              title: 'Invited Talk 1',
            },
            Speaker: 'Yoshua Bengio',
            title: 'TBD',
            institution: 'Professor, Université deMontréal; Founder, Mila',
            logoSrc: '',
            link: 'https://yoshuabengio.org/',
            duration: '40',
          },
          {
            time: '2025-12-06T09:50:00-07:00',
            theme: {
              title: 'Invited Talk 2',
            },
            Speaker: 'Ahmad Beirami',
            title: 'TBD',
            institution: 'Research Scientist, Google DeepMind',
            logoSrc: '',
            link: 'https://beirami.github.io/',
            duration: '40',
          },
          {
            time: '2025-12-06T10:30:00-07:00',
            theme: {
              title: 'Coffee Break',
            },
            Speaker: 'Poster Session',
            institution: '',
            logoSrc: '',
            link: '',
            duration: '50',
          },
          {
            time: '2025-12-06T11:20:00-07:00',
            theme: {
              title: 'Invited Talk 3',
            },
            Speaker: 'Furong Huang',
            title: 'TBD',
            institution: 'Associate Professor, UMD',
            logoSrc: '',
            link: 'https://furong-huang.com/',
            duration: '40',
          },
          {
            time: '2025-12-06T12:00:00-07:00',
            theme: {
              title: 'Oral Presentation',
            },
            Speaker: 'TBD',
            title: 'TBD',
            institution: '',
            logoSrc: '',
            link: '',
            duration: '30',
          },
          {
            time: '2025-12-06T12:30:00-07:00',
            theme: {
              title: 'Lunch',
            },
            Speaker: '-',
            title: 'Lunch',
            institution: '',
            logoSrc: '',
            link: '',
            duration: '90',
          },
          {
            time: '2025-12-06T14:00:00-07:00',
            theme: {
              title: 'Invited Talk 4',
            },
            Speaker: 'Bo Li',
            title: 'TBD',
            institution: 'Associate Professor, UIUC; Director, Secure Learning Lab',
            logoSrc: '',
            link: 'https://aisecure.github.io/',
            duration: '40',
          },
          {
            time: '2025-12-06T14:40:00-07:00',
            theme: {
              title: 'Invited Talk 5',
            },
            Speaker: 'Yu Yang',
            title: 'TBD',
            institution: 'Research Scientist, OpenAI',
            logoSrc: '',
            link: 'https://sites.google.com/view/yuyang0901/home',
            duration: '40',
          },
          {
            time: '2025-12-06T15:20:00-07:00',
            theme: {
              title: 'Oral Presentation',
            },
            Speaker: 'TBD',
            title: 'TBD',
            institution: '',
            logoSrc: '',
            link: '',
            duration: '30',
          },
          {
            time: '2025-12-06T15:50:00-07:00',
            theme: {
              title: 'Invited Talk 6',
            },
            Speaker: 'Yihe Deng',
            title: 'TBD',
            institution: 'Ph.D. Candidate, UCLA; Student Researcher, Google',
            logoSrc: '',
            link: 'https://yihe-deng.notion.site/yihe-deng-main',
            duration: '40',
          },
          {
            time: '2025-12-06T16:30:00-07:00',
            theme: {
              title: 'Panel Discussion',
            },
            Speaker: 'Panelists: Junchi Yan (SJTU); Zhangyang Atlas Wang (XTX Markets & UT Austin); Atsushi Nitanda (A*STAR & NTU); Maksym Andriushchenko (EPFL); Yihe Deng (UCLA)',
            title: 'From Theory to Deployment: Process-Level Safety in LRMs',
            institution: '',
            logoSrc: '',
            link: '',
            duration: '40',
          },
          {
            time: '2025-12-06T17:10:00-07:00',
            theme: {
              title: 'Interactive Breakout',
            },
            Speaker: '-',
            title: 'Breakout Session',
            institution: '',
            logoSrc: '',
            link: '',
            duration: '30',
          },
          {
            time: '2025-12-06T017:40:00-07:00',
            theme: {
              title: 'Closing Remark',
            },
            Speaker: 'Wei Huang',
            title: 'Closing Remark',
            institution: 'Research Scientist, RIKEN AIP',
            logoSrc: '',
            link: 'https://weihuang05.github.io/',
            duration: '20',
          },
        ]}
      />
    </Fragment>
    <Fragment slot="bg">
      <div class="absolute inset-0 bg-blue-50 dark:bg-transparent"></div>
    </Fragment>
  </Content>

  <Content id="Call-For-Papers">
    <Fragment slot="title">Call for Papers</Fragment>
    <Fragment slot="subtitle">Description</Fragment>
    <Fragment slot="content"
      ><div class="mb-4">
        Recent breakthroughs in large reasoning models (LRMs)—systems that perform explicit, multi-step inference at test time—have unlocked impressive gains across science,
        mathematics, and law (Guo et al., 2025; Snell et al., 2024). Yet these very reasoning chains introduce novel trust risks that scale-only LLM studies overlook: small logic slips can
        snowball, intermediate states become new attack surfaces, and plausible-but-false proofs can elude standard output-level filters (Geiping et al., 2025).
      </div>
      <div class="mb-4">
        <span class="font-bold">What sets this workshop apart</span>: Prior workshops focused on generic robustness; This workshop aims to bring together researchers and practitioners to systematically explore,
        characterize, and address these emergent trust risks in large reasoning models. We seek to move beyond traditional evaluation of final LLM outputs, instead focusing on the full process
        of reasoning: how errors propagate, how uncertainty compounds, how transparency and accountability are affected, and what new opportunities exist for robust evaluation and
        intervention (Zhu et al., 2025; Ouyang et al., 2024).
      </div>
      <div class="mb-4"><span class="font-bold">Core Research Questions</span></div>
      <ul class="list-outside list-disc">
        <li>Risk Landscape — Which process-level failure modes threaten high-stakes deployment?</li>
        <li>Metric Design — How can we measure and benchmark step-wise safety at scale?</li>
        <li>Prototype Validation — What lightweight tools or model patches can we release now to seed wider research?</li>
      </ul>
      <div class="mb-4"><span class="font-bold">Topics of Interest</span></div>
      <ul class="list-outside list-disc">
        <li>Failure modes and risk propagation in multi-step reasoning</li>
        <li>Adversarial attacks and defenses in inference-time reasoning.</li>
        <li>Evaluation metrics and empirical benchmarks for reasoning safety.</li>
        <li>Uncertainty quantification, error detection, and correction in reasoning processes.</li>
        <li>Approaches for improving interpretability and transparency of reasoning chains.</li>
        <li>Causal analysis as one lens for understanding reasoning failures.</li>
        <li>Human-AI trust, calibration, and collaborative reasoning.</li>
        <li>Case studies of reasoning models in real-world high-stakes domains.</li>
        <li>New architectures or algorithms for safer, more robust reasoning.</li>
      </ul>
    </Fragment>
  </Content>

  <Content id="Submission-Guide" classes={{ container: 'pb-2 md:pb-2 lg:pb-2' }}>
    <Fragment slot="title">Submission Guide</Fragment>
    <Fragment slot="subtitle">Submission Instructions</Fragment>
    <Fragment slot="content"
      ><div class="mb-4">
        We invite submissions of up to 8 pages (excluding references and appendices). The main manuscript and any appendices must be submitted as a single PDF file through the
        <a
          href="https://openreview.net"
          class="hover:underline text-sky-600 font-medium"
          target="_blank">OpenReview</a
        > portal (the official workshop venue link will be posted on the website). Papers previously published at other conferences will not be considered for acceptance
      </div>
      <div class="mb-4">
        Each paper receives <span class="font-bold">no less than 3 reviews</span>. Reviewers declare the conflict of interests via the OpenReview interface; organizers will not handle papers with which they have a conflict.
      </div>
    </Fragment>
    <Fragment slot="bg">
      <div class="absolute inset-0 bg-blue-50 dark:bg-transparent"></div>
    </Fragment>
  </Content>
  <Content classes={{ container: 'py-2 md:py-2 lg:py-2 pb-12 md:pb-12 lg:pb-12' }}>
    <Fragment slot="subtitle">Timelines</Fragment>
    <Fragment slot="content" classes={{ container: 'p-0' }}>
      <div class="flex justify-center">
        <table class="bg-white">
          <tbody>
            <tr>
              <td class="w-64 border px-4 py-2">Submissions Deadline</td>
              <td class="w-64 border px-4 py-2">Aug 22th, 2025</td>
            </tr>
            <tr class="bg-gray-50">
              <td class="border px-4 py-2">Reviewer bidding dates</td>
              <td class="border px-4 py-2">Aug 22 - 26th, 2025</td>
            </tr>
            <tr>
              <td class="border px-4 py-2">Review Deadline</td>
              <td class="border px-4 py-2">Sept 17th, 2025</td>
            </tr>
            <tr class="bg-gray-50">
              <td class="border px-4 py-2">Paper Notification Date</td>
              <td class="border px-4 py-2">Sept 22th, 2025</td>
            </tr>
            <tr>
              <td class="border px-4 py-2">Camera Ready Deadline</td>
              <td class="border px-4 py-2">Nov 5th, 2025</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="flex py-4">
        All deadlines are specified in 23:59<a
          href="https://www.timeanddate.com/time/zones/aoe"
          class="hover:underline text-sky-600 font-medium px-2"
          target="_blank">AoE</a
        > (Anywhere on Earth).
      </div>
    </Fragment>
    <Fragment slot="bg">
      <div class="absolute inset-0 bg-blue-50 dark:bg-transparent"></div>
    </Fragment>
  </Content>
 
  <Brands
    id="Organizers"
    title="Organizing Committee"
    icons={[]}
    images={[
      {
        src: '/zhanpeng_zhou.jpg',
        alt: 'zhanpeng_zhou',
        name: 'Zhanpeng Zhou',
        university: 'SJTU',
        bioLink: 'https://zzp1012.github.io/',
      },
      {
        src: '/wei_huang.jpeg',
        alt: 'wei_huang',
        name: 'Wei Huang',
        university: 'RIKEN AIP',
        bioLink: 'https://weihuang05.github.io/',
      },
      {
        src: '/mingyuan_bai.jpeg',
        alt: 'mingyuan_bai',
        name: 'Mingyuan Bai',
        university: 'RIKEN AIP',
        bioLink: 'https://scholar.google.com.au/citations?user=lo0_2rMAAAAJ&hl=zh-CN',
      },
      {
        src: '/krikamol_muandet.jpeg',
        alt: 'krikamol_muandet',
        name: 'Krikamol Muandet',
        university: 'CISPA',
        bioLink: 'http://krikamol.org/',
      },

      {
        src: '/kun_zhang.jpeg',
        alt: 'kun_zhang',
        name: 'Kun Zhang',
        university: 'CMU & MBZUAI',
        bioLink: 'http://www.andrew.cmu.edu/user/kunz1/',
      },
      {
        src: '/taiji_suzuki.jpg',
        alt: 'taiji_suzuki',
        name: 'Taiji Suzuki',
        university: 'UTokyo & RIKEN AIP',
        bioLink: 'http://ibis.t.u-tokyo.ac.jp/suzuki/',
      },
    ]}
    >
  </Brands>

  <Brands
    id="Speakers & Panelists"
    title="Speakers & Panelists"
    icons={[]}
    images={[
      {
        src: '/ahmad_beirami.jpg',
        alt: 'organizer01',
        name: 'Ahmad Beirami',
        university: 'Google DeepMind',
        bioLink: 'https://beirami.github.io/',
      },
      {
        src: '/yoshua_bengio.jpg',
        alt: 'yoshua_bengio',
        name: 'Yoshua Bengio',
        university: ' Université deMontréal; Mila',
        bioLink: 'https://yoshuabengio.org/',
      },
      {
        src: '/furong_huang.jpg',
        alt: 'furong_huang',
        name: 'Furong Huang',
        university: 'UMD',
        bioLink: 'https://furong-huang.com/',
      },
      {
        src: '/bo_li.jpg',
        alt: 'bo_li',
        name: 'Bo Li',
        university: 'UIUC; Secure Learning Lab',
        bioLink: 'https://aisecure.github.io//',
      },

      {
        src: '/yu_yang.jpg',
        alt: 'yu_yang',
        name: 'Yu Yang',
        university: 'OpenAI',
        bioLink: 'https://sites.google.com/view/yuyang0901/home',
      },
      {
        src: '/yihe_deng.jpg',
        alt: 'yihe_deng',
        name: 'Yihe Deng',
        university: 'UCLA',
        bioLink: 'https://yihe-deng.notion.site/yihe-deng-main',
      },
      {
        src: '/junchi_yan.jpeg',
        alt: 'junchi_yan',
        name: 'Junchi Yan',
        university: 'SJTU',
        bioLink: 'https://thinklab.sjtu.edu.cn/',
      },
      {
        src: '/zhangyang_wang.jpeg',
        alt: 'zhangyang_wang',
        name: 'Zhangyang Atlas Wang',
        university: 'XTX Markets & UT Austin',
        bioLink: 'https://vita-group.github.io/index.html',
      },
      {
        src: '/atsushi_nitanda.png',
        alt: 'atsushi_nitanda',
        name: 'Atsushi Nitanda',
        university: 'A*STAR & NTU',
        bioLink: 'https://sites.google.com/site/atsushinitanda',
      },
      {
        src: '/maksym_andriushchenko.jpg',
        alt: 'maksym_andriushchenko',
        name: 'Maksym Andriushchenko',
        university: 'EPFL',
        bioLink: 'https://www.andriushchenko.me/',
      },
    ]}
    >
    <Fragment slot="bg">
      <div class="absolute inset-0 bg-blue-50 dark:bg-transparent"></div>
    </Fragment>
  </Brands>

  <Content id="Program-Committee">
    <Fragment slot="title"> Program Committee </Fragment>
    <Fragment slot="content">
      <div class="max-w-6xl flex flex-wrap mx-auto">
        <div class="pc-item">Zijun Chen (SJTU)</div>
        <div class="pc-item">Yi Liu (CityU HK)</div>
        <div class="pc-item">Yi Ding (Purdue)</div>
        <div class="pc-item">Zhuang Luo (Meta)</div>
        <div class="pc-item">Bowei He (CityU HK, MBZUAI)</div>
        <div class="pc-item">Zachary Yang (McGill)</div>
        <div class="pc-item">Nathan Roll (Stanford)</div>
        <div class="pc-item">Weijie Xu (Amazon)</div>
        <div class="pc-item">Yihao Zhang (PKU)</div>
        <div class="pc-item">Jungang Li (HKUST)</div>
        <div class="pc-item">Kejia Chen (ZJU)</div>
        <div class="pc-item">Yuechen Jiang (UH Mānoa)</div>
      </div>
      <div
        id="pcContent"
        class="overflow-hidden max-h-0 transition-max-height duration-700 ease-in-out max-w-6xl flex flex-wrap mx-auto"
      >
        <div class="pc-item">Yang Li (SJTU)</div>
        <div class="pc-item">Shaobo Wang (SJTU)</div>
        <div class="pc-item">Jianhao Huang (SJTU)</div>
        <div class="pc-item">Qibing Ren (SJTU)</div>
        <div class="pc-item">Tongcheng Zhang (SJTU)</div>
        <div class="pc-item">Xiaoxuan Lei (McGill)</div>
        <div class="pc-item">Shan Chen (Harvard)</div>
        <div class="pc-item">Xueying Ma (Columbia)</div>
        <div class="pc-item">Junqi Jinag (ICL)</div>
        <div class="pc-item">Qin Liu (UC Davis)</div>
        <div class="pc-item">Weiwei Jiang (BUPT)</div>
        <div class="pc-item">Zhexu Liu (RPI)</div>
        <div class="pc-item">Hongyi Liu (Amazon)</div>
        <div class="pc-item">Lingyun Wang (Pitt)</div>
        <div class="pc-item">Yingzhou Lu (Stanford)</div>
        <div class="pc-item">Yicheng Fu (Stanford)</div>
        <div class="pc-item">Xinhe Xu (UIUC)</div>
        <div class="pc-item">Mingyang Wang (LMU)</div>
        <div class="pc-item">Andy Su (Meta & Princeton)</div>
        <div class="pc-item">Jishen Yang (Amazon)</div>
        <div class="pc-item">Simin Fan (EPFL)</div>
        <div class="pc-item">Yibo Miao (CAS)</div>
        <div class="pc-item">Gyuwan Kim (UCSB)</div>
        <div class="pc-item">Shraddha Barke (Microsoft)</div>
        <div class="pc-item">Xiangjun Dong (Texas A&M)</div>
        <div class="pc-item">Atharva Kulkarni (USC)</div>
        <div class="pc-item">Ruixuan Liu (Emory)</div>
        <div class="pc-item">Zhexin Zhang (THU)</div>
        <div class="pc-item">Caihua Li (Yale)</div>
        <div class="pc-item">Yongyi Yang (UMich)</div>
        <div class="pc-item">Mao Cheng (Meta)</div>
        <div class="pc-item">Huaijin Wu (SJTU)</div>
        <div class="pc-item">Lei Yu (Meta)</div>
        <div class="pc-item">He Zhang (RMIT)</div>
        <div class="pc-item">Saptarshi Saha (ISIK)</div>
        <div class="pc-item">Xia Song (NTU)</div>
        <div class="pc-item">Fiez Hussein Khleaf KHLEAF (Sakarya)</div>
        <div class="pc-item">Ryotaro Kawata (UTokyo)</div>
        <div class="pc-item">Rei Higuchi (UTokyo)</div>
        <div class="pc-item">Naoki Nishikawa (UTokyo)</div>
        <div class="pc-item">Chengyuan Deng (Rutgers)</div>
        <div class="pc-item">Fanhu Zeng (CAS)</div>
        <div class="pc-item">Zhiwei Xu (UMich)</div>
        <div class="pc-item">Binh Nguyen (NUS)</div>
        <div class="pc-item">Yunting Yin (EMU)</div>
        <div class="pc-item">Jiawei Yan (Roche)</div>
        <div class="pc-item">Jiahao Yuan (ECNU)</div>
        <div class="pc-item">Shurui Li (Waymo)</div>
        <div class="pc-item">Siqi Cao (JHU)</div>
        <div class="pc-item">Youngsun Lim (Boston)</div>
      </div>
      <div class="flex justify-center mt-8"><Button id="pcExpandButton" class="cursor-pointer"> Expand </Button></div>
      <style>
        .pc-item {
          width: 25%;
          box-sizing: border-box;
          text-align: center;
          margin-bottom: 0.4rem;
          margin-top: 0.4rem;
        }
      </style>
      <script>
        const pcButton = document.getElementById('pcExpandButton');
        const pcContent = document.getElementById('pcContent');
        let isPcOpen = false;
        if (pcButton && pcContent) {
          pcButton.addEventListener('click', () => {
            if (!isPcOpen) {
              pcContent.style.maxHeight = pcContent.scrollHeight + 'px';
              pcButton.textContent = 'Collapse';
              isPcOpen = true;
            } else {
              pcContent.style.maxHeight = '';
              pcButton.textContent = 'Expand';
              isPcOpen = false;
            }
          });
        }
      </script>
    </Fragment>
  </Content>
  <!-- FAQs Widget ******************* -->

  <FAQs
    title="Frequently Asked Questions"
    items={[
      {
        title: 'Can we submit a paper that will also be submitted to NeurIPS 2025?',
        description: 'Yes.',
        icon: 'tabler:help-octagon',
      },
      {
        title: 'Can we submit a paper that was accepted at ICML 2025?',
        description: 'No. ICML prohibits main conference publication from appearing concurrently at the workshops.',
        icon: 'tabler:help-octagon',
      },
      {
        title: 'Will the reviews be made available to authors?',
        description: 'Yes.',
        icon: 'tabler:help-octagon',
      },
      {
        title: 'I have a question not addressed here, whom should I contact?',
        description: 'Email organizers at trustllm-workshop@googlegroups.com',
        icon: 'tabler:help-octagon',
      },
    ]}
    ><Fragment slot="bg">
      <div class="absolute inset-0 bg-blue-50 dark:bg-transparent"></div>
    </Fragment></FAQs
  >

  <Content id="References">
    <Fragment slot="title"> References </Fragment>

    <Fragment slot="content">
      <p class="text-slate-500">
        [1] Guo, D., Yang, D., Zhang, H., Song, J., Zhang, R., Xu, R., Zhu, Q., Ma, S., Wang, P., Bi, X. and Zhang, X., 2025. Deepseek-R1: Incentivizing reasoning capability in LLMs via
        reinforcement learning. arXiv preprint arXiv:2501.12948.
      </p>
      <p class="text-slate-500">
        [2] Snell, C., Lee, J., Xu, K. and Kumar, A., 2024. Scaling LLM test-time compute optimally
        can be more effective than scaling model parameters. arXiv preprint arXiv:2408.03314.
      </p>
      <p class="text-slate-500">
        [3] Muennighoff, N., Yang, Z., Shi, W., Li, X.L., Fei-Fei, L., Hajishirzi, H., Zettlemoyer, L.,
        Liang, P., Candès, E. and Hashimoto, T., 2025. s1: Simple test-time scaling. arXiv preprint arXiv:2501.19393.
      </p>
      <p class="text-slate-500">
        [4] Geiping, J., McLeish, S., Jain, N., Kirchenbauer, J., Singh, S., Bartoldson, B.R.,
        Kailkhura, B., Bhatele, A. and Goldstein, T., 2025. Scaling up Test-Time Compute with Latent
        Reasoning: A Recurrent Depth Approach. arXiv preprint arXiv:2502.05171.
      </p>
      <p class="text-slate-500">
        [5] Zhu, J., Yan, L., Wang, S., Yin, D. and Sha, L., 2025. Reasoning-to-defend: Safety-aware
        reasoning can defend large language models from Jailbreaking. arXiv preprint arXiv:2502.12970.
      </p>
    </Fragment>
  </Content>
</Layout>
